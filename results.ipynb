{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import urllib.parse\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import src.data.data_loader as data_loader\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn', Mutes warnings when copying a slice from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths, paths_finished, paths_unfinished = data_loader.load_paths()\n",
    "articles = data_loader.load_articles()\n",
    "categories = data_loader.load_categories()\n",
    "links = data_loader.load_links()\n",
    "distance_matrix = data_loader.load_distance_matrix()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frustration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial approach to measuring player frustration focuses on analyzing instances of backtracking. When players need to retrace their steps within a game, it often signals an increase in difficulty, which can be directly linked to frustration. Let's dive into it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Across the study, we have {len(paths_finished)} finished paths, while {len(paths_unfinished)} remain unfinished, for a total of {len(all_paths)} paths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average number of backtracks for finished vs unfinished paths\n",
    "avg_backtracks_finished = all_paths[all_paths['status'] == 'finished']['backtracks'].apply(len).mean()\n",
    "avg_backtracks_unfinished = all_paths[all_paths['status'] != 'finished']['backtracks'].apply(len).mean()\n",
    "\n",
    "# Output the results\n",
    "print(\"\\nAverage number of backtracks per game:\")\n",
    "print(f\"Finished paths: {avg_backtracks_finished:.2f}\")\n",
    "print(f\"Unfinished paths: {avg_backtracks_unfinished:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get finished games with and without backtracks\n",
    "\n",
    "finished_with_bt = paths_finished[paths_finished['backtracks'].apply(len) > 0]\n",
    "finished_no_bt = paths_finished[paths_finished['backtracks'].apply(len) == 0]\n",
    "\n",
    "# Calculate average duration for each group\n",
    "avg_duration_with_bt = finished_with_bt['durationInSec'].median()\n",
    "avg_duration_no_bt = finished_no_bt['durationInSec'].median()\n",
    "\n",
    "# Group finished games by number of backtracks and calculate median duration\n",
    "backtrack_counts = paths_finished.groupby(paths_finished['backtracks'].apply(len)).size()\n",
    "backtrack_durations = paths_finished.groupby(paths_finished['backtracks'].apply(len))['durationInSec'].median()\n",
    "\n",
    "# Filter to keep only counts with at least 10 samples\n",
    "filtered_counts = backtrack_counts[backtrack_counts >= 10]\n",
    "filtered_durations = backtrack_durations[filtered_counts.index]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(filtered_durations.index, filtered_durations.values, marker='o')\n",
    "plt.axvline(x=avg_backtracks_finished, color='r', linestyle='--', label='Average backtracks')\n",
    "plt.axhline(y=avg_duration_with_bt, color='g', linestyle='--', label='Average duration')\n",
    "plt.xlabel('Number of Backtracks')\n",
    "plt.ylabel('Median Duration (seconds)')\n",
    "plt.title('Median Game Duration vs Number of Backtracks (10+ samples)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a trend line\n",
    "z = np.polyfit(filtered_durations.index, filtered_durations.values, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(filtered_durations.index, p(filtered_durations.index), \"r--\", alpha=0.8, \n",
    "         label=f'Trend line (slope: {z[0]:.1f})')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(filtered_durations.values, p(filtered_durations.index))\n",
    "\n",
    "plt.legend()\n",
    "plt.text(0.05, 0.95, f'R-squared: {r_squared:.4f}', transform=plt.gca().transAxes, \n",
    "         verticalalignment='top')\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts of games with each number of backtracks:\")\n",
    "print(filtered_counts)\n",
    "print(f\"\\nR-squared value: {r_squared:.4f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today’s fast-paced world, where content is rapidly consumed, players’ attention spans are increasingly shorter. If a game drags on too long, frustration can build as players wait longer for the rewarding sense of completion. As illustrated in the graph above, there is a noticeable correlation between the frequency of backtracking and overall game duration: each backtrack adds an average of 43 seconds to the game time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group finished games by number of backtracks and calculate median duration\n",
    "backtrack_counts = paths_finished.groupby(paths_finished['backtracks'].apply(len)).size()\n",
    "backtrack_ratings = paths_finished.groupby(paths_finished['backtracks'].apply(len))['rating'].mean()\n",
    "\n",
    "# Filter to keep only counts with at least 10 samples\n",
    "filtered_counts = backtrack_counts[backtrack_counts >= 10]\n",
    "filtered_ratings = backtrack_ratings[filtered_counts.index]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(filtered_ratings.index, filtered_ratings.values, marker='o')\n",
    "plt.xlabel('Number of Backtracks')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.axvline(x=avg_backtracks_finished, color='r', linestyle='--', label='Average backtracks')\n",
    "plt.axhline(y=paths_finished['rating'].mean(), color='g', linestyle='--', label='Average rating')\n",
    "plt.title('Average Rating vs Number of Backtracks (10+ samples)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a trend line\n",
    "z = np.polyfit(filtered_ratings.index, filtered_ratings.values, 1)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "plt.plot(filtered_ratings.index, p(filtered_ratings.index), \"r--\", alpha=0.8, \n",
    "         label=f'Trend line (slope: {z[0]:.1f})')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(filtered_ratings.values, p(filtered_ratings.index))\n",
    "\n",
    "plt.legend()\n",
    "plt.text(0.05, 0.95, f'R-squared: {r_squared:.4f}', transform=plt.gca().transAxes, \n",
    "         verticalalignment='top')\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts of games with each number of backtracks:\")\n",
    "print(filtered_counts)\n",
    "print(f\"\\nR-squared value: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask for paths with backtracking and valid ratings\n",
    "has_backtrack_mask = paths_finished['path'].str.contains('<')\n",
    "has_rating_mask = paths_finished['rating'].notna()\n",
    "\n",
    "# Filter ratings into two groups\n",
    "ratings_with_backtrack = paths_finished.loc[has_backtrack_mask & has_rating_mask, 'rating']\n",
    "ratings_without_backtrack = paths_finished.loc[~has_backtrack_mask & has_rating_mask, 'rating']\n",
    "\n",
    "# Calculate averages using pandas methods\n",
    "average_back = ratings_with_backtrack.mean()\n",
    "average_no_back = ratings_without_backtrack.mean()\n",
    "\n",
    "\n",
    "# Plot the histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(ratings_with_backtrack, bins=5, color='orange', edgecolor='black', alpha=0.7, label='With Backtracking')\n",
    "plt.hist(ratings_without_backtrack, bins=5, color='skyblue', edgecolor='black', alpha=0.7, label='Without Backtracking')\n",
    "\n",
    "# Add vertical lines for the averages\n",
    "plt.axvline(x=average_back, color='red', linestyle='-', linewidth=2, label=f'Average (with backtracking) = {average_back:.2f}')\n",
    "plt.axvline(x=average_no_back, color='blue', linestyle='-', linewidth=2, label=f'Average (without backtracking) = {average_no_back:.2f}')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(1,6))\n",
    "plt.title('Histogram of Ratings for Paths With and Without Backtracking')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other indicator of player frustration we consider is the game’s \"difficulty rating\" assigned by the player upon completion. Generally, as the difficulty of a game increases, so does the rating, offering a potential correlation with the level of frustration experienced. If the player needs to backtrack, the perceived difficulty of the game seems higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame with counts of backtracks and traversed\n",
    "backtracks = pd.Series(all_paths['backtracks'].explode().dropna().tolist())\n",
    "traversed = pd.Series(all_paths['traversed'].explode().dropna().tolist())\n",
    "\n",
    "word_counts = pd.DataFrame({\n",
    "    'backtracks': backtracks.value_counts(),\n",
    "    'traversed': traversed.value_counts()\n",
    "})\n",
    "\n",
    "# Calculate the ratio of backtracks to traversed\n",
    "word_counts['backtrack_ratio'] = word_counts['backtracks'] / word_counts['traversed']\n",
    "\n",
    "# Fill NaN values with 0 (for words that were traversed but never backtracked)\n",
    "word_counts['backtrack_ratio'] = word_counts['backtrack_ratio'].fillna(0)\n",
    "\n",
    "# Sort by the ratio in descending order\n",
    "word_counts_sorted = word_counts.sort_values('backtrack_ratio', ascending=False)\n",
    "\n",
    "# Display the top 20 words with highest backtrack ratios for words with at least 100 occurrences\n",
    "print(word_counts_sorted[word_counts_sorted['traversed'] >= 0].head(20))\n",
    "\n",
    "# Optional: Plot the distribution of backtrack ratios\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(word_counts['backtrack_ratio'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Backtrack Ratios')\n",
    "plt.xlabel('Backtrack Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_unfinished.groupby('type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of games in each 'type' group\n",
    "game_counts_by_type = paths_unfinished.groupby('type').size()\n",
    "\n",
    "# Display the result\n",
    "print(game_counts_by_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, it’s evident that the game induces a certain level of frustration for players, with our backtracking analysis supporting this observation. The next step is to delve into understanding the causes of this frustration, particularly identifying what aspects of the game design lead to the need for backtracking."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of backtrack-target pairs\n",
    "backtrack_df = pd.DataFrame([\n",
    "    {'backtrack': backtrack, 'target': row['target']}\n",
    "    for _, row in all_paths[all_paths['backtracks'].apply(len) > 0][['backtracks','target']].iterrows()\n",
    "    for backtrack in row['backtracks']\n",
    "])\n",
    "\n",
    "print(\"\\nArticle of backtrack vs target\")\n",
    "print(backtrack_df.value_counts().head(20))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve observed that numerous backtracks stem from confusion over closely related words or concepts. Could this reveal gaps or missing connections within the game’s design that prevent players from progressing/finishing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing targets \n",
    "articles_set = set(articles['article'])\n",
    "missing_targets = set([target for target in paths_unfinished['target'] if target not in articles_set])\n",
    "\n",
    "if missing_targets:\n",
    "    print(\"Missing targets:\")\n",
    "    for target in missing_targets:\n",
    "        print(target)\n",
    "else:\n",
    "    print(\"No missing targets found.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, there are missing connections—and, even more frustratingly, some destinations are entirely unreachable. Imagine the player’s frustration in searching for “Christmas,” only to complete the game on “Santa Claus” and realize there’s no link back to “Christmas.” This lack of connection not only disrupts gameplay but can also leave players feeling stuck and unsatisfied, amplifying their frustration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess if a link is needed between two articles and measure their \"distance,\" we can use:\n",
    "\n",
    "- **Shortest Path**: Count the hops between articles in the dataset. A high hop count suggests a possible need for a direct link.\n",
    "- **Cosine Similarity**: Calculate similarity between article embeddings. High similarity without a link may indicate a need for connection.\n",
    "The heatmap below shows the differences between these two methods : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace -1 values with np.nan to ignore them during normalization\n",
    "distance_matrix_normalized = np.where(distance_matrix == -1, np.nan, distance_matrix)\n",
    "\n",
    "# Step 2: Perform normalization on the matrix, excluding NaN values\n",
    "min_value = np.nanmin(distance_matrix_normalized)\n",
    "max_value = np.nanmax(distance_matrix_normalized)\n",
    "distance_matrix_normalized = (distance_matrix_normalized - min_value) / (max_value - min_value)\n",
    "\n",
    "# Step 3: Replace NaNs (original -1 values) with 1\n",
    "distance_matrix_normalized = np.where(np.isnan(distance_matrix_normalized), 1, distance_matrix_normalized)\n",
    "\n",
    "\n",
    "min_value = np.nanmin(distance_matrix_normalized)\n",
    "max_value = np.nanmax(distance_matrix_normalized)\n",
    "distance_matrix_normalized = (distance_matrix_normalized - min_value) / (max_value - min_value)\n",
    "\n",
    "# Step 3: Replace NaNs (original -1 values) with 1\n",
    "distance_matrix_normalized = np.where(np.isnan(distance_matrix_normalized), 1, distance_matrix_normalized)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(distance_matrix_normalized, cmap=\"YlGnBu\", annot=False, cbar=True)\n",
    "plt.title('Heatmap of Normalized Distance Matrix')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Choice of similarity model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at that game, it will also enable us to select which model we want to use for the rest of the analysis to compute the similarity between 2 articles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from src.utils.similarity import get_cosine_similarity_for_path_word_by_word, get_cosine_similarity_for_path_word_by_word_openai\n",
    "from src.utils.utils import path_to_list\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "clip_model = SentenceTransformer(\"clip-ViT-B-32\", device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "christmas_path=\"Bob_Dylan;England;Church_of_England;Christianity;Jesus;Trinity;Christianity;Bible;God;United_States;Turkey_%28bird%29;Domesticated_turkey;A_Christmas_Carol;Bob_Marley;Ethiopia;Meat;Chicken;Poultry;Food;Season;Winter;Snow;Bonobo;Human;Culture;Ice_age;Earth;Middle_Ages;Holy_Roman_Empire;Switzerland;World_War_I;Finland;Arctic_Circle;Greenland;Iceland;Denmark;German_language;Hebrew_language;Rome;Roman_Catholic_Church;Anglicanism;Roman_Britain;Gold;Olympic_Games;1896_Summer_Olympics;Austria;World_War_II;Jew;Religion;Sun;Sunlight;<;Solar_eclipse;Planet;Saturn;Zeus;Greek_mythology;Agriculture;<;Apollo;Roman_mythology;Ancient_Rome;Christianity;Jesus;Last_Supper;Wine;Alcohol;<;Nutmeg;Tree;Chestnut;Bread;Europe;Russia;Lithuania;Poland;Potato;Dill;Soup;Egg_%28food%29;Food;Advertising;<;Pottery;Coal;Santa_Claus\"\n",
    "christmas_path = path_to_list(christmas_path)\n",
    "bert_similarities = get_cosine_similarity_for_path_word_by_word(christmas_path, \"Christmas\", sb_model)\n",
    "clip_similarities = get_cosine_similarity_for_path_word_by_word(christmas_path, \"Christmas\", clip_model)\n",
    "openai_similarities = get_cosine_similarity_for_path_word_by_word_openai(christmas_path, \"Christmas\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(range(len(christmas_path)), bert_similarities, marker='o', label='SentenceBERT')\n",
    "plt.plot(range(len(christmas_path)), clip_similarities, marker='o', label='CLIP')\n",
    "plt.plot(range(len(christmas_path)), openai_similarities, marker='o', label='OpenAI')\n",
    "plt.title('Path to Christmas')\n",
    "plt.xlabel('Step in Path') \n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Add path words as x-tick labels\n",
    "plt.xticks(range(len(christmas_path)), christmas_path, rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a thorough and meticulous analysis of various models—including SentenceBERT, CLIP, and OpenAI— We selected the OpenAI model for its superior accuracy and consistency in delivering precise results through cosine similarity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First test of threshold to find missing links : Fixed threshold on the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.similarity import should_have_link\n",
    "\n",
    "#using arbitrary threshold\n",
    "print(should_have_link(\"Santa Claus\",\"Christmas\"))\n",
    "print(should_have_link(\"Santa Claus\",\"Summer\"))\n",
    "print(should_have_link(\"Soybean\",\"Bean\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find potential missing links between articles based on semantic similarity\n",
    "should_link_dict = {}\n",
    "missing_link_pairs = []\n",
    "\n",
    "# Iterate through all articles\n",
    "for source_article in tqdm(articles['article'][:100]):#only 100 articles to limit runtime\n",
    "    # Get existing links from current article\n",
    "    existing_links = links[links['linkSource'] == source_article]\n",
    "    full_source_article = open(f\"data/plaintext_articles/{urllib.parse.quote(source_article.replace(' ', '_'))}.txt\",\"r\").read()\n",
    "    source_article_lowered = full_source_article.lower()\n",
    "\n",
    "    # Find articles that aren't currently linked from source article\n",
    "    potential_targets = articles[~articles['article'].isin(existing_links['linkTarget'])]\n",
    "    potential_targets = potential_targets[potential_targets['article'].str.lower().apply(lambda x: x in source_article_lowered)]\n",
    "    potential_targets = potential_targets[potential_targets['article'].apply(lambda x: should_have_link(source_article,x)[0])]\n",
    "    potential_targets = potential_targets[potential_targets['article'] != source_article]\n",
    "    \n",
    "    \n",
    "    if len(potential_targets) > 0:\n",
    "        should_link_dict[source_article]= potential_targets['article'].tolist()\n",
    "        for target in potential_targets['article']:\n",
    "            missing_link_pairs.append({\n",
    "                'source': source_article,\n",
    "                'target': target\n",
    "            })\n",
    "\n",
    "\n",
    "for article,targets in should_link_dict.items():\n",
    "    print(f\"{article}: {targets}\")\n",
    "\n",
    "pd.DataFrame(missing_link_pairs).to_csv('data/missing_links.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this initial iteration, the model appears to perform well, allowing us to easily add additional links. It identifies article titles mentioned within the text that are not yet linked, even when they are semantically close. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a better way to do it ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s analyze the similarities across the entire game by calculating the similarity between each page and the target article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path_similarities_unfinished, all_path_similarities_finished = data_loader.load_all_path_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the last 10 elements of each path\n",
    "from src.utils.utils import shorten_list_finished, shorten_list_unfinished\n",
    "\n",
    "all_path_similarities_unfinished_copy = all_path_similarities_unfinished.copy()\n",
    "all_path_similarities_unfinished_copy['similarities'],all_path_similarities_unfinished_copy['path'] = zip(*all_path_similarities_unfinished_copy.apply(shorten_list_unfinished_, axis=1))\n",
    "\n",
    "similarities_unfinished = all_path_similarities_unfinished_copy[all_path_similarities_unfinished_copy['similarities'].apply(lambda x: len(x) > 0)][['similarities','path','target']]\n",
    "\n",
    "\n",
    "all_path_similarities_finished_copy = all_path_similarities_finished.copy()\n",
    "all_path_similarities_finished_copy['similarities'],all_path_similarities_finished_copy['path'] = zip(*all_path_similarities_finished_copy.apply(shorten_list_finished, axis=1))\n",
    "similarities_finished = all_path_similarities_finished_copy['similarities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure with subplots for the first 10 paths\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 25))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Colors for each model\n",
    "colors = {\n",
    "    'similarities': 'green'\n",
    "}\n",
    "\n",
    "selected_finished = all_path_similarities_finished_copy.sample(10)\n",
    "# Plot first 10 paths\n",
    "for i in range(10):\n",
    "    path = selected_finished.apply(lambda x: x['path'],axis=1).iloc[i]\n",
    "    target = selected_finished['target'].iloc[i]\n",
    "    \n",
    "    # Plot each model's similarities\n",
    "    for model in ['similarities']:\n",
    "        similarities = selected_finished.apply(lambda x: x[model],axis=1).iloc[i]\n",
    "        axes[i].plot(range(len(similarities)), similarities, \n",
    "                    marker='o', label=model, color=colors[model])\n",
    "    \n",
    "    # Customize the plot\n",
    "    axes[i].set_title(f'Path {i+1}\\nTarget: {target}')\n",
    "    axes[i].set_xlabel('Step in Path')\n",
    "    axes[i].set_ylabel('Cosine Similarity')\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].grid(True)\n",
    "    axes[i].legend()\n",
    "    \n",
    "    # Add path words as x-tick labels\n",
    "    axes[i].set_xticks(range(len(path)))\n",
    "    axes[i].set_xticklabels(path, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mhhhhh, it seems like there is a trend over there !!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot similarity evolution for 100 paths together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot first 100 similarity evolutions\n",
    "random_finished = all_path_similarities_finished_copy.sample(100)\n",
    "for index, path in random_finished.iterrows():\n",
    "    similarities = path['similarities']\n",
    "    reversed_similarities = similarities[::-1]\n",
    "    plt.plot(reversed_similarities)\n",
    "\n",
    "\n",
    "plt.xlabel('distance to end of game')\n",
    "plt.ylabel('Similarity Score') \n",
    "plt.xlim(9,0)\n",
    "plt.title('Evolution of Similarities for First 100 Paths')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all completed games, we observe a clear trend in the endgame stage. Let’s examine whether this trend extends to unfinished games as well (excluding the final step, of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.similarity import process_similarities\n",
    "\n",
    "similarities_by_distance_finished = process_similarities(similarities_finished)\n",
    "similarities_by_distance_unfinished = process_similarities(similarities_unfinished['similarities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means, medians, and standard deviations\n",
    "stats = {\n",
    "    'Finished': [similarities_by_distance_finished, range(10)],\n",
    "    'Unfinished': [similarities_by_distance_unfinished, range(1,10)]\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "colors = ['#1f77b4', '#2ca02c']\n",
    "\n",
    "for i, (path_type, (similarities, x)) in enumerate(stats.items()):\n",
    "    means = [np.mean(sublist) for sublist in similarities]\n",
    "    stds = [np.std(sublist) for sublist in similarities]\n",
    "    \n",
    "    plt.plot(x, means, color=colors[i], label=f'Mean ({path_type})', linewidth=2)\n",
    "    plt.fill_between(x, [m - s for m, s in zip(means, stds)],\n",
    "                     [m + s for m, s in zip(means, stds)],\n",
    "                     color=colors[i], alpha=0.2)\n",
    "\n",
    "plt.xlabel('Distance from End', fontsize=12)\n",
    "plt.ylabel('Average Similarity Score', fontsize=12)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(9,0)\n",
    "plt.title('Mean Similarity Score vs Distance from End', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis confirms a trend in the endgame stage, even within unfinished paths. To investigate this, we focused on the highest similarity point within each game and the last eight moves leading up to it. This trend reveals several possible scenarios:\n",
    "\n",
    "- **Player Confusion**: Some players appear to struggle, failing to reach a similarity threshold of 0.3. In such cases, the game might be disregarded by the search algorithm, as the low similarity indicates a lack of meaningful progression.\n",
    "\n",
    "- **Missed Links**: Players may overlook critical links if they appear later in the article rather than at the beginning. This suggests a potential improvement area in link placement to aid player navigation. (Refer to the accompanying graph for a visual representation.)\n",
    "\n",
    "- **Missing Final Link**: In some cases, there may be a missing link between the last article the player reached and the target, creating a gap in progression and heightening player frustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_links_df =pd.read_csv('data/chosen_links_rank.csv')\n",
    "\n",
    "\n",
    "rank_data = chosen_links_df['RankChosen'].dropna()\n",
    "\n",
    "# Count the frequency of each rank\n",
    "rank_counts = rank_data.value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(rank_counts.index, rank_counts.values, color='skyblue')\n",
    "plt.xlabel('Position of Chosen Link in Article')\n",
    "plt.xlim(1, 30)  # Limit to first 20 positions\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Chosen Links Based on Position in Article')\n",
    "\n",
    "# Set x-ticks to show every position within the limited range\n",
    "plt.xticks(range(1, 31))  # Adjust as necessary\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find missing link with our new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.similarity import get_missing_links\n",
    "\n",
    "unfinished_missing_links = similarities_unfinished.apply(get_missing_links,axis=1)\n",
    "print(\"Most common pairs of articles that may be missing links:\")\n",
    "print(unfinished_missing_links.value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter pairs that appear at least 2 times\n",
    "frequent_pairs = unfinished_missing_links.value_counts()[unfinished_missing_links.value_counts() >= 2]\n",
    "link_missed_by_player = []\n",
    "link_absent = []\n",
    "\n",
    "for source, target in frequent_pairs.index:\n",
    "    full_source_article = open(f\"data/plaintext_articles/{urllib.parse.quote(source.replace(' ', '_'))}.txt\",\"r\").read()\n",
    "    source_article_lowered = full_source_article.lower()\n",
    "    if links[(links['linkSource'] == source) & (links['linkTarget'] == target)].shape[0] > 0:\n",
    "        link_missed_by_player.append((source,target))\n",
    "    elif target.lower() in source_article_lowered:\n",
    "        link_absent.append((source,target))\n",
    "\n",
    "\n",
    "print(f\"Link missed by player: {len(link_missed_by_player)}\")\n",
    "print(f\"Link absent: {len(link_absent)}\")\n",
    "\n",
    "# Save missing links to CSV\n",
    "missing_links_df = pd.DataFrame(link_absent, columns=['source', 'target'])\n",
    "missing_links_df.to_csv('data/missing_links.csv', index=False)\n",
    "\n",
    "# Save links missed by players to CSV \n",
    "missed_by_player_df = pd.DataFrame(link_missed_by_player, columns=['source', 'target'])\n",
    "missed_by_player_df.to_csv('data/links_missed_by_player.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can happily classify each of the unfinished game :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have officially saved Christmas, allowing Santa Claus to join the party ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
